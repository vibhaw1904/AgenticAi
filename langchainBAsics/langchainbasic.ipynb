{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16119e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I want to clarify that I'm Claude, an AI assistant created by Anthropic. I aim to be direct and honest about who I am. How can I help you today?\", additional_kwargs={}, response_metadata={'id': 'msg_01RTGWDKCbq1zgBKHCcbYdkV', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 13, 'output_tokens': 41, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--494ea5b2-edec-4924-9292-b4a271db9801-0', usage_metadata={'input_tokens': 13, 'output_tokens': 41, 'total_tokens': 54, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "\n",
    "if not os.environ.get(\"ANTHROPIC_API_KEY\"):\n",
    "      os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter API key for Anthropic: \")\n",
    "\n",
    "\n",
    "model = init_chat_model(\"claude-3-5-sonnet-latest\", model_provider=\"anthropic\")\n",
    "\n",
    "\n",
    "model.invoke(\"Hello, vibhaw!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fe947a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here are two key benefits of using LangChain:\\n\\n1. Chain Management & Composition:\\n- LangChain makes it easy to combine multiple AI operations into sequential chains\\n- You can break complex tasks into smaller, manageable components and chain them together\\n- It provides a clean way to organize and reuse different language model interactions\\n\\n2. Built-in Abstractions & Integrations:\\n- LangChain offers pre-built components for common tasks like document loading, text splitting, and vector storage\\n- It provides ready-to-use integrations with popular services and databases\\n- This saves development time as you don't need to build these integrations from scratch\\n\\nThese features make LangChain particularly useful for building complex LLM-powered applications while reducing boilerplate code and implementation complexity.\", additional_kwargs={}, response_metadata={'id': 'msg_01DPmYAnQDXEHiJ3N5XND5xi', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 22, 'output_tokens': 175, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--59205718-32f6-48c6-8bc3-8a9c2bdcf6fb-0', usage_metadata={'input_tokens': 22, 'output_tokens': 175, 'total_tokens': 197, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create message \n",
    "messsgaes = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"what are two benefits of using  langchain\"),]\n",
    "model.invoke(messsgaes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
