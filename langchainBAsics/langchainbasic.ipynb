{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16119e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I want to clarify that I'm Claude, an AI assistant created by Anthropic, not Vibhaw. I aim to be direct and honest about who and what I am. How can I help you today?\", additional_kwargs={}, response_metadata={'id': 'msg_015p3GZXC4EbyQ3DtWXpGBCb', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 13, 'output_tokens': 49, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--b473c5be-0664-441e-9d9b-94e058b7f648-0', usage_metadata={'input_tokens': 13, 'output_tokens': 49, 'total_tokens': 62, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "if not os.environ.get(\"ANTHROPIC_API_KEY\"):\n",
    "      os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter API key for Anthropic: \")\n",
    "\n",
    "\n",
    "model = init_chat_model(\"claude-3-5-sonnet-latest\", model_provider=\"anthropic\")\n",
    "\n",
    "\n",
    "model.invoke(\"Hello, vibhaw!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fe947a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are two key benefits of using LangChain:\\n\\n1. Chain Composition and Modularity:\\n- LangChain allows you to easily combine multiple AI operations into chains of tasks\\n- You can break down complex workflows into smaller, reusable components\\n- Makes it simpler to create sophisticated AI applications by connecting different tools and models in a modular way\\n\\n2. Built-in Abstractions and Integrations:\\n- Provides pre-built components for common operations like memory management, document loading, and text splitting\\n- Offers ready-to-use integrations with various LLMs (like GPT-3, GPT-4) and vector stores\\n- Reduces boilerplate code and speeds up development by providing consistent interfaces for different AI services\\n\\nThese features make LangChain particularly valuable for building complex AI applications while keeping the code organized and maintainable.', additional_kwargs={}, response_metadata={'id': 'msg_01Smvmf6aAqGpoQkEvb3oJY9', 'model': 'claude-3-5-sonnet-20241022', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 22, 'output_tokens': 192, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-3-5-sonnet-20241022'}, id='run--54360524-e938-4cb8-ab99-585690a2005d-0', usage_metadata={'input_tokens': 22, 'output_tokens': 192, 'total_tokens': 214, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create message \n",
    "messsgaes = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"what are two benefits of using  langchain\"),]\n",
    "model.invoke(messsgaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ed3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are two key benefits of using LangChain:\n",
      "\n",
      "1. Chain Management and Composition:\n",
      "- LangChain makes it easy to combine multiple AI operations into sequential chains\n",
      "- You can create complex workflows by connecting different components (prompts, models, memory, etc.)\n",
      "- Helps organize and manage the flow of data between different parts of your AI application\n",
      "\n",
      "2. Built-in Abstractions and Integrations:\n",
      "- Provides pre-built components for common tasks (document loading, text splitting, vector stores, etc.)\n",
      "- Offers integrations with multiple LLM providers (OpenAI, Hugging Face, etc.)\n",
      "- Reduces boilerplate code and makes it easier to switch between different tools and services\n",
      "\n",
      "These features make LangChain particularly useful for building complex LLM-powered applications while keeping the code organized and maintainable."
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(messsgaes):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76734af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##dynamic prompt template\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "##create translation app\n",
    "\n",
    "\n",
    "translation_template=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "       ( \"system\",\n",
    "        \"You are a helpful assistant that translates {source_language} to {target_language}.maintain the tone and style\",),\n",
    "        (\"user\",\n",
    "        \"Translate the following text from {source_language} to {target_language}: {text}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "##\n",
    "prompt=translation_template.invoke({\n",
    "    \"source_language\": \"English\",\n",
    "    \"target_language\": \"French\",\n",
    "    \"text\": \"lanchchain is a framework for developing applications powered by language models.\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defdbf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La langchain est un cadre de développement pour créer des applications alimentées par des modèles de langage."
     ]
    }
   ],
   "source": [
    "model.invoke(prompt)\n",
    "for chunk in model.stream(prompt):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
